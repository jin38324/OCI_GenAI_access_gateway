{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import oci\n",
    "config = oci.config.from_file('~/.oci/config', 'GENERATEAI')\n",
    "compartment_id = config[\"compartment_id\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "generative_ai_client = oci.generative_ai.GenerativeAiClient(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_models_response = generative_ai_client.list_models(compartment_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cohere.command-r-16k',\n",
       " 'cohere.command-r-plus',\n",
       " 'cohere.command-r-16k',\n",
       " 'meta.llama-3-70b-instruct',\n",
       " 'meta.llama-3-70b-instruct',\n",
       " 'meta.llama-2-70b-chat',\n",
       " 'cohere.command',\n",
       " 'cohere.command-light',\n",
       " 'cohere.command',\n",
       " 'cohere.command',\n",
       " 'cohere.command-light',\n",
       " 'cohere.embed-english-light-v3.0',\n",
       " 'cohere.embed-english-v3.0',\n",
       " 'cohere.embed-multilingual-light-v3.0',\n",
       " 'cohere.embed-multilingual-v3.0',\n",
       " 'cohere.command',\n",
       " 'cohere.command',\n",
       " 'cohere.command-light',\n",
       " 'cohere.command-light',\n",
       " 'cohere.embed-english-light-v2.0',\n",
       " 'cohere.command']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avaliable_models = [i.display_name for i in list_models_response.data.items]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_details = {\n",
    "  \"compartmentId\": compartment_id,\n",
    "  \"servingMode\": {\n",
    "    \"modelId\": \"cohere.command-r-16k\",\n",
    "    \"servingType\": \"ON_DEMAND\"\n",
    "  },\n",
    "  \"chatRequest\": {\n",
    "    \"message\": \"Tell me something about the company's relational database.\",\n",
    "    \"maxTokens\": 600,\n",
    "    \"isStream\": False,\n",
    "    \"apiFormat\": \"COHERE\",\n",
    "    \"frequencyPenalty\": 1.0,\n",
    "    \"presencePenalty\": 0,\n",
    "    \"temperature\": 0.75,\n",
    "    \"topP\": 0.7,\n",
    "    \"topK\": 1,\n",
    "    \"documents\": [\n",
    "      {\n",
    "        \"title\": \"Oracle\",\n",
    "        \"snippet\": \"Oracle database services and products offer customers cost-optimized and high-performance versions of Oracle Database, the world's leading converged, multi-model database management system, as well as in-memory, NoSQL and MySQL databases. Oracle Autonomous Database, available on premises via Oracle Cloud@Customer or in the Oracle Cloud Infrastructure, enables customers to simplify relational database environments and reduce management workloads.\",\n",
    "        \"website\": \"https://www.oracle.com/database\"\n",
    "      }\n",
    "    ],\n",
    "    \"chatHistory\": [\n",
    "      {\n",
    "        \"role\": \"USER\",\n",
    "        \"message\": \"Tell me something about Oracle.\"\n",
    "      },\n",
    "      {\n",
    "        \"role\": \"CHATBOT\",\n",
    "        \"message\": \"Oracle is one of the largest vendors in the enterprise IT market and the shorthand name of its flagship product. The database software sits at the center of many corporate IT\"\n",
    "      }\n",
    "    ]\n",
    "  }\n",
    "}\n",
    "\n",
    "generative_ai_inference_client = oci.generative_ai_inference.GenerativeAiInferenceClient(config)\n",
    "response = generative_ai_inference_client.chat(chat_details)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\n",
       "  \"chat_response\": {\n",
       "    \"api_format\": \"COHERE\",\n",
       "    \"chat_history\": [\n",
       "      {\n",
       "        \"message\": \"Tell me something about Oracle.\",\n",
       "        \"role\": \"USER\"\n",
       "      },\n",
       "      {\n",
       "        \"message\": \"Oracle is one of the largest vendors in the enterprise IT market and the shorthand name of its flagship product. The database software sits at the center of many corporate IT\",\n",
       "        \"role\": \"CHATBOT\",\n",
       "        \"tool_calls\": null\n",
       "      },\n",
       "      {\n",
       "        \"message\": \"Tell me something about the company's relational database.\",\n",
       "        \"role\": \"USER\"\n",
       "      },\n",
       "      {\n",
       "        \"message\": \"Oracle Database Services provide customers with different versions of Oracle Database, which is a converged multi-model database management system. The database offers in-memory, NoSQL, and MySQL databases. Additionally, The Oracle Autonomous Database simplifies relational database environments and decreases management workloads, offering a unique service.\",\n",
       "        \"role\": \"CHATBOT\",\n",
       "        \"tool_calls\": null\n",
       "      }\n",
       "    ],\n",
       "    \"citations\": [\n",
       "      {\n",
       "        \"document_ids\": [\n",
       "          \"doc_0\"\n",
       "        ],\n",
       "        \"end\": 66,\n",
       "        \"start\": 48,\n",
       "        \"text\": \"different versions\"\n",
       "      },\n",
       "      {\n",
       "        \"document_ids\": [\n",
       "          \"doc_0\"\n",
       "        ],\n",
       "        \"end\": 85,\n",
       "        \"start\": 70,\n",
       "        \"text\": \"Oracle Database\"\n",
       "      },\n",
       "      {\n",
       "        \"document_ids\": [\n",
       "          \"doc_0\"\n",
       "        ],\n",
       "        \"end\": 147,\n",
       "        \"start\": 98,\n",
       "        \"text\": \"converged multi-model database management system.\"\n",
       "      },\n",
       "      {\n",
       "        \"document_ids\": [\n",
       "          \"doc_0\"\n",
       "        ],\n",
       "        \"end\": 177,\n",
       "        \"start\": 168,\n",
       "        \"text\": \"in-memory\"\n",
       "      },\n",
       "      {\n",
       "        \"document_ids\": [\n",
       "          \"doc_0\"\n",
       "        ],\n",
       "        \"end\": 184,\n",
       "        \"start\": 179,\n",
       "        \"text\": \"NoSQL\"\n",
       "      },\n",
       "      {\n",
       "        \"document_ids\": [\n",
       "          \"doc_0\"\n",
       "        ],\n",
       "        \"end\": 206,\n",
       "        \"start\": 190,\n",
       "        \"text\": \"MySQL databases.\"\n",
       "      },\n",
       "      {\n",
       "        \"document_ids\": [\n",
       "          \"doc_0\"\n",
       "        ],\n",
       "        \"end\": 251,\n",
       "        \"start\": 225,\n",
       "        \"text\": \"Oracle Autonomous Database\"\n",
       "      },\n",
       "      {\n",
       "        \"document_ids\": [\n",
       "          \"doc_0\"\n",
       "        ],\n",
       "        \"end\": 295,\n",
       "        \"start\": 252,\n",
       "        \"text\": \"simplifies relational database environments\"\n",
       "      },\n",
       "      {\n",
       "        \"document_ids\": [\n",
       "          \"doc_0\"\n",
       "        ],\n",
       "        \"end\": 330,\n",
       "        \"start\": 300,\n",
       "        \"text\": \"decreases management workloads\"\n",
       "      }\n",
       "    ],\n",
       "    \"documents\": [\n",
       "      {\n",
       "        \"id\": \"doc_0\",\n",
       "        \"snippet\": \"Oracle database services and products offer customers cost-optimized and high-performance versions of Oracle Database, the world's leading converged, multi-model database management system, as well as in-memory, NoSQL and MySQL databases. Oracle Autonomous Database, available on premises via Oracle Cloud@Customer or in the Oracle Cloud Infrastructure, enables customers to simplify relational database environments and reduce management workloads.\",\n",
       "        \"title\": \"Oracle\",\n",
       "        \"website\": \"https://www.oracle.com/database\"\n",
       "      }\n",
       "    ],\n",
       "    \"error_message\": null,\n",
       "    \"finish_reason\": \"COMPLETE\",\n",
       "    \"is_search_required\": null,\n",
       "    \"prompt\": null,\n",
       "    \"search_queries\": null,\n",
       "    \"text\": \"Oracle Database Services provide customers with different versions of Oracle Database, which is a converged multi-model database management system. The database offers in-memory, NoSQL, and MySQL databases. Additionally, The Oracle Autonomous Database simplifies relational database environments and decreases management workloads, offering a unique service.\",\n",
       "    \"tool_calls\": null\n",
       "  },\n",
       "  \"model_id\": \"cohere.command-r-16k\",\n",
       "  \"model_version\": \"1.2\"\n",
       "}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "host = \"http://127.0.0.1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"status\":\"OK\"}'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "route = \"/health\"\n",
    "headers={'Authorization': 'Bearer ocigenerativeai'}\n",
    "res = requests.get(host + route,headers=headers)\n",
    "res.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"object\":\"list\",\"data\":[{\"id\":\"meta.llama-3-70b-instruct\",\"created\":1722217416,\"object\":\"model\",\"owned_by\":\"ocigenerativeai\"},{\"id\":\"cohere.command-r-16k\",\"created\":1722217416,\"object\":\"model\",\"owned_by\":\"ocigenerativeai\"},{\"id\":\"cohere.command-r-plus\",\"created\":1722217416,\"object\":\"model\",\"owned_by\":\"ocigenerativeai\"}]}'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "route = \"/api/v1/models\"\n",
    "headers={'Authorization': 'Bearer ocigenerativeai'}\n",
    "res = requests.get(host + route,headers=headers)\n",
    "res.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"detail\":\"Unsupported Model Id\"}'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "route = \"/api/v1/models/cohere.embed-multilingual-v3\"\n",
    "\n",
    "headers={'Authorization': 'Bearer ocigenerativeai'}\n",
    "res = requests.get(host + route,headers=headers)\n",
    "res.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"object\":\"list\",\"data\":[{\"object\":\"embedding\",\"embedding\":[0.0020771027,0.055511475,-0.04397583,0.0\n"
     ]
    }
   ],
   "source": [
    "route = \"/api/v1/embeddings\"\n",
    "\n",
    "headers={'Authorization': 'Bearer ocigenerativeai'}\n",
    "data = {\n",
    "  \"model\": \"cohere.embed-multilingual-v3.0\",\n",
    "  \"input\": [\n",
    "    \"Your text string goes here\"\n",
    "  ]\n",
    "}\n",
    "res = requests.post(host + route,headers=headers,json=data)\n",
    "print(res.text[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"id\":\"3133EDDF4B9C4045A086C4865D488C7D/1D90EFFE8FC59FC1D7F0D4C166784461/209EE86C0E7B0DA9A449052C27DB55C1\",\"created\":1721983330,\"model\":\"cohere.command-r-16k\",\"system_fingerprint\":\"fp\",\"choices\":[{\"index\":0,\"finish_reason\":\"complete\",\"logprobs\":null,\"message\":{\"role\":\"assistant\",\"content\":\"As an AI assistant, I don't have access to real-time weather information or ‡§õ‡§π. Below is a general description of the climate in each city though: \\n\\n**San Francisco, USA:** San Francisco's climate is pleasant and mild throughout the year. The city experiences a temperate marine climate, often cooled by fog, especially in the summer months. The average high temperature in San Francisco in the summer is around 65¬∞F to 70¬∞F (18¬∞C to 21¬∞C), while the winters are cooled by fog and rain, with temperatures rarely dropping below 40¬∞F (4¬∞C).\\n\\n**Tokyo, Japan:** Tokyo typically enjoys a humid subtropical climate, with hot and humid summers and mild to cool winters. Summer temperatures often reach into the 80s Fahrenheit (20s Celsius), while winters can see temperatures hovering around 40¬∞F to 50¬∞F (4¬∞C to 10¬∞C). Tokyo also experiences a wet season from June to September, with heavy rainfall.\\n\\n**Paris, Canada:** Paris has a continental climate, which means hot summers and cold winters. The city's summer temperatures can reach the 70¬∞F to 80¬∞F (20¬∞C to 25¬∞C), while winters can be frigid with temperatures dipping below 30¬∞F (-1¬∞C), and frequent snow. Paris experiences a moderate rainfall pattern throughout the year.\\n\\nRemember, these are generalclusions, and the actual weather in these cities can vary greatly based on the time of year, geographic location, and other factors. For precise current weather information, I recommend checking a reliable weather website or using a weather application on your device.\"}}],\"object\":\"chat.completion\",\"usage\":{\"prompt_tokens\":0,\"completion_tokens\":0,\"total_tokens\":0}}\n"
     ]
    }
   ],
   "source": [
    "route = \"/api/v1/chat/completions\"\n",
    "\n",
    "headers={'Authorization': 'Bearer ocigenerativeai'}\n",
    "data = {\n",
    "  \"stram\": False,\n",
    "  \"model\": \"cohere.command-r-16k\",\n",
    "  \"messages\": [\n",
    "    {\n",
    "      \"role\": \"system\",\n",
    "      \"content\": \"You are a helpful assistant.\"\n",
    "    },\n",
    "    {\n",
    "      \"role\": \"user\",\n",
    "      \"content\": \"What's the weather like in San Francisco, Tokyo, and Paris?\"\n",
    "    }\n",
    "  ],\n",
    "  \"tools\":[\n",
    "        {\n",
    "            \"type\": \"function\",\n",
    "            \"function\": {\n",
    "                \"name\": \"get_current_weather\",\n",
    "                \"description\": \"Get the current weather in a given location\",\n",
    "                \"parameters\": {\n",
    "                    \"type\": \"object\",\n",
    "                    \"properties\": {\n",
    "                        \"location\": {\n",
    "                            \"type\": \"string\",\n",
    "                            \"description\": \"The city and state, e.g. San Francisco, CA\",\n",
    "                        },\n",
    "                        \"unit\": {\"type\": \"string\", \"enum\": [\"celsius\", \"fahrenheit\"]},\n",
    "                    },\n",
    "                    \"required\": [\"location\"],\n",
    "                },\n",
    "            },\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "}\n",
    "res = requests.post(host + route,headers=headers,json=data)\n",
    "print(res.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "import oci,json\n",
    "config = oci.config.from_file('~/.oci/config', 'GENERATEAI')\n",
    "compartment_id = config[\"compartment_id\"]\n",
    "generative_ai_inference_client = oci.generative_ai_inference.GenerativeAiInferenceClient(config)\n",
    "\n",
    "body = {\"compartmentId\": \"ocid1.compartment.oc1..aaaaaaaals7mmltwjf3h2dfl3aflyxqgbsguk6b73mrn4oq7ywsl5r35lhjq\", \n",
    "        \"servingMode\": {\"modelId\": \"meta.llama-3-70b-instruct\", \"servingType\": \"ON_DEMAND\"}, \n",
    "        \"chatRequest\": {\"apiFormat\": \"GENERIC\", \n",
    "                        \"messages\": [{\"role\": \"USER\", \"content\": [{\"type\": \"TEXT\", \"text\": \"Hello!\"}]}], \n",
    "                        \"numGenerations\": 1, \n",
    "                        \"maxTokens\": 2048, \"isStream\": True, \"frequencyPenalty\": 0.0, \"presencePenalty\": 0.0, \"temperature\": 1.0, \"topP\": 1.0,\"topK\":-1}}\n",
    "\n",
    "response = generative_ai_inference_client.chat(body)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<oci._vendor.sseclient.SSEClient at 0x19de3e173d0>"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0B9B7BA4FCC74EA7999875023C653B79/31689E310926976993345F165B9F3F7E/B24241919F768BF1B3A5802CC78AABFB'"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.request_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ÊµãËØï"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model: meta.llama-3-70b-instruct\n",
      "User: Hello!\n",
      "Assistant: Hello! It's nice to meet you. Is there something I can help you with, or would you like to chat?\n",
      "****************************************************************************************************\n",
      "model: cohere.command-r-16k\n",
      "User: Hello!\n",
      "Assistant: Hi! I'm Flora, and I'm here to help make conversations as pleasant as possible üòä How can I assist you today?\n",
      "****************************************************************************************************\n",
      "model: cohere.command-r-plus\n",
      "User: Hello!\n",
      "Assistant: Hello! How can I be of assistance today?\n",
      "****************************************************************************************************\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(\n",
    "    api_key = \"ocigenerativeai\",\n",
    "    base_url = \"http://127.0.0.1/api/v1/\",\n",
    "    )\n",
    "models = client.models.list()\n",
    "message = \"Hello!\"\n",
    "\n",
    "# Test chat completions\n",
    "for model in models:\n",
    "    print(\"model:\", model.id)\n",
    "    print(\"User:\", message)\n",
    "    completion = client.chat.completions.create(\n",
    "        model=model.id,\n",
    "        messages=[{\"role\": \"user\", \"content\": message}],\n",
    "        )\n",
    "    print(\"Assistant:\", completion.choices[0].message.content)\n",
    "    print(\"*\"*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model: meta.llama-3-70b-instruct\n",
      "User: Hello!\n",
      "Assistant:Hello! It's nice to meet you. Is there something I can help you with, or would you like to chat?\n",
      " ****************************************************************************************************\n",
      "model: cohere.command-r-16k\n",
      "User: Hello!\n",
      "Assistant:Hi there! Good day to you! I'm Coral, an AI chatbot who's here to help you anyway I can. What do you have in mind?\n",
      " ****************************************************************************************************\n",
      "model: cohere.command-r-plus\n",
      "User: Hello!\n",
      "Assistant:Hello, how can I help you?\n",
      " ****************************************************************************************************\n"
     ]
    }
   ],
   "source": [
    "# Test chat completions with streaming response\n",
    "for model in models:\n",
    "    print(\"model:\", model.id)\n",
    "    print(\"User:\", message)\n",
    "    print(\"Assistant:\", end='')\n",
    "    response = client.chat.completions.create(\n",
    "        model=model.id,\n",
    "        messages=[{'role': 'user', 'content': message}],\n",
    "        stream=True  # this time, we set stream=True\n",
    "    )\n",
    "    for chunk in response:\n",
    "        if chunk.choices[0].delta.content:\n",
    "            print(chunk.choices[0].delta.content,end='')\n",
    "    print('\\n',\"*\"*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model: cohere.embed-english-light-v3.0\n",
      "0 : [0.049652099609375, 0.03176879882812 ...... 0823211669921875, 0.021026611328125]\n",
      "1 : [-0.0679931640625, -0.05831909179687 ...... 0200042724609375, 0.040069580078125]\n",
      "****************************************************************************************************\n",
      "model: cohere.embed-english-v3.0\n",
      "0 : [-0.016204833984375, 0.0127410888671 ...... 0.02081298828125, 0.020172119140625]\n",
      "1 : [-0.01422882080078125, -0.0110321044 ...... 021820068359375, 0.0208587646484375]\n",
      "****************************************************************************************************\n",
      "model: cohere.embed-multilingual-light-v3.0\n",
      "0 : [-0.0186614990234375, 0.032897949218 ...... 396728515625, 0.0010957717895507812]\n",
      "1 : [0.03826904296875, 0.01397705078125, ...... 0.0872802734375, 0.0298614501953125]\n",
      "****************************************************************************************************\n",
      "model: cohere.embed-multilingual-v3.0\n",
      "0 : [-0.006072998046875, 0.0305786132812 ...... 62652587890625, -0.0186920166015625]\n",
      "1 : [-0.00855255126953125, 0.04284667968 ...... 9741783142089844, -0.04559326171875]\n",
      "****************************************************************************************************\n"
     ]
    }
   ],
   "source": [
    "embd_model=[ 'cohere.embed-english-light-v3.0',\n",
    "            'cohere.embed-english-v3.0',\n",
    "            'cohere.embed-multilingual-light-v3.0',\n",
    "            'cohere.embed-multilingual-v3.0']\n",
    "input = [\"hello!\",\"‰Ω†Â•ΩÔºÅ\"]\n",
    "for model in embd_model:\n",
    "    print(\"model:\",model)\n",
    "    response = client.embeddings.create(input = input, model=model).data\n",
    "    for each in response:\n",
    "        print(each.index,':',str(each.embedding)[:36],'......',str(each.embedding)[-36:])\n",
    "    print(\"*\"*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
